#! /bin/bash
#
#   Manages LizardFS metadata server in full and shadow master modes
#
#   Copyright (C) 2014  EditShare LLC
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 3 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software Foundation,
#   Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA
#
#######################################################################
#
#   Manages the personality of LizardFS metadata server nodes as an OCF resource.
#   Starts nodes in shadow master state, with an invalid master.  When it receives
#   notification of which node will be promoted to master, it switches its
#   master to that node.  When promoted to master, it changes personality to
#   full master, and when demoted it stops the daemon and starts it back up
#   again in shadow master mode.
#
#######################################################################
#
#   TODO:
#   - check LizardFS metadata server to ensure it isn't configured to start at boot
#   - check permissions and configuration file sanity
#   - use lizardfs-admin information to set priorities for shadow masters
#     to determine which one is the best candidate to promote to master
#   - Add support for running only in master mode (if, for instance, we're
#     a master writing to an underlying replicated filesystem, and want to
#     use Pacemaker to manage which node we're on), instead of requiring
#     master/slave
#
#######################################################################

: ${OCF_ROOT:=/usr/lib/ocf}
: ${OCF_FUNCTIONS_DIR:=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs

# Usage: read_cfg_var <config_file> <VARNAME> <sep> <DEFAULT_VALUE>
read_cfg_var() {
	local cfg_file=${1}
	local var=${2}
	local sep=${3:-=}
	local default_value=${4}
	{
	echo "${default_value}"
	sed -e 's/[[:blank:]]*#.*$//' -n \
			-e 's/^[[:blank:]]*'"${var}"'[[:blank:]]*'"${sep}"'[[:blank:]]*\(.*\)$/\1/p' "$cfg_file"
	} | tail -n 1
}

# Parameters for this resource agent, with default values

OCF_RESKEY_master_cfg_default=/etc/mfs/mfsmaster.cfg

: ${OCF_RESKEY_master_cfg:=$OCF_RESKEY_master_cfg_default}

# Convenience variables

lock_timeout=10  # seconds
score_master=1000
score_shadow_lastest=900
score_shadow_connected=500
score_shadow_no_metadata=0
metadata_version_attribute_name="lizardfs-metadata-version"

# Core LizardFS variables

failover_ip=$(read_cfg_var ${OCF_RESKEY_master_cfg} MASTER_HOST)
admin_password=$(read_cfg_var ${OCF_RESKEY_master_cfg} ADMIN_PASSWORD)
data_dir=$(read_cfg_var ${OCF_RESKEY_master_cfg} DATA_PATH = /var/lib/mfs)
matocl_host=$(read_cfg_var ${OCF_RESKEY_master_cfg} MATOCL_LISTEN_HOST = '*')
matocl_port=$(read_cfg_var ${OCF_RESKEY_master_cfg} MATOCL_LISTEN_PORT = 9421)
lizardfs_user=$(read_cfg_var ${OCF_RESKEY_master_cfg} WORKING_USER = mfs)
lizardfs_group=$(read_cfg_var ${OCF_RESKEY_master_cfg} WORKING_GROUP = mfs)
exports_cfg=$(read_cfg_var ${OCF_RESKEY_master_cfg} EXPORTS_FILENAME = /etc/mfs/mfsexports.cfg)

master_metadata=${data_dir}/metadata.mfs
master_lock=${data_dir}/metadata.mfs.lock
master_backup_logs=${data_dir}/changelog.mfs.*
promote_mode="prevent"

# Debugging variables:  These may aid in attempting to debug what corosync and pacemaker are doing.
# sed -i 's%debug: off%debug: on%' /etc/corosync/corosync.conf # To enable normal & noisy debugging.
# Normally the /tmp folder is ethereal while /var/tmp/ is persistent, using /tmp folder by default.
# touch /tmp/lfs-debug to enable some useful debugging log messages and touching at state changes.
debug_state_change_logs=$(read_cfg_var ${OCF_RESKEY_master_cfg} DEBUG_STATE_CHANGE = /tmp)
debug="" ; if [[ -f $debug_state_change_logs/lfs-debug ]] ; then debug=1; fi

# About

usage() {
cat<<EOF
usage: $0 (start|stop|monitor|validate-all|meta-data}

$0 manages a collection of LizardFS master nodes to manage which one is the
  current full master and which ones are shadow masters

The 'start' operation starts mfsmaster as a shadow master
The 'stop' operation stops mfsmaster
The 'monitor' operation checks if mfsmaster is running and whether
  it's a shadow master
The 'promote' operation promotes a shadow master to a full master
The 'demote' operation shuts down the master and restarts it as a shadow master
The 'notify' operation notifies a shadow master of the current full master
The 'validate-all' option checks whether the configuration is valid
The 'meta-data' option returns the XML metadata describing this resource
  agent for front-end tools
EOF
}

lizardfs_ra_metadata() {
cat <<EOF
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="metadataserver-resource-agent" version="0.1">
  <version>0.1</version>
  <longdesc lang="en">
Manages the personality of LizardFS metadata server nodes as an OCF resource.
Starts nodes in shadow master state, with an invalid master.  When it receives
notification of which node will be promoted to master, it switches its
master to that node.  When promoted to master, it changes personality
to full master, and when demoted it stops the daemon and starts it back
up again in shadow master mode.
  </longdesc>
  <shortdesc lang="en">
Manages the shadow master state of LizardFS metadata server resources
  </shortdesc>
  <parameters>
    <parameter name="master_cfg" unique="0" required="0">
      <longdesc lang="en">
Config file for LizardFS metadata server; will find in config_dir if not specified.
      </longdesc>
      <shortdesc lang="en">
        Config file for LizardFS metadata server
      </shortdesc>
      <content type="string" default="$OCF_RESKEY_master_cfg_default"/>
    </parameter>
  </parameters>
  <actions>
    <action name="start"        timeout="45" />
    <action name="stop"         timeout="45" />
    <action name="monitor"      timeout="20"
                                depth="0" interval="20" role="Slave" />
    <action name="monitor"      timeout="20"
                                depth="0" interval="10" role="Master" />
    <action name="reload"       timeout="20" />
    <action name="promote"      timeout="45" />
    <action name="demote"       timeout="45" />
    <!--action name="notify"       timeout="20" /-->
    <action name="meta-data"    timeout="5" />
    <action name="validate-all" timeout="5" />
  </actions>
</resource-agent>
EOF
}


# Utilities

lizardfs_master() {
	local command=$1
	local personality=$2
	mfsmaster -c "$OCF_RESKEY_master_cfg" -o ha-cluster-managed -o initial-personality="${personality}" "${command}"
#	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-M_${personality}_${command}
}

# Actions

lizardfs_master_start_shadow() {
	lizardfs_master_monitor
	case $? in
		$OCF_RUNNING_MASTER)
			msg="LizardFS metadata server already running in master mode"
			ocf_log warn "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_RUNNING_MASTER
		;;
		$OCF_SUCCESS)
			msg="LizardFS metadata server already running as a shadow master"
			ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_SUCCESS
		;;
		*)	msg="starting LizardFS metadata server as shadow master"
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	esac

	if ! ensure_dirs ; then
		return ${?}
	fi

	# When the start action is called, we are supposed to start in the
	# slave state, which means starting a shadow master.

	ocf_run lizardfs_master start shadow
	msg="starting LizardFS metadata server as shadow master"
	ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-StartS
}

metadataserver_really_stop() {
	if ocf_run lizardfs_master stop ; then
		return $OCF_SUCCESS
	else
		msg="failed to stop LizardFS metadata server, killing instead"
		ocf_log warn "$msg" ; test $debug && ocf_log notice "$msg" 
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Kill
		if ocf_run lizardfs_master kill ; then
			return $OCF_SUCCESS
		else
			return $OCF_ERR_GENERIC
		fi
	fi
}

lizardfs_master_stop() {
	# Stop the master, if it's running
	lizardfs_master_monitor
	case $? in
		$OCF_RUNNING_MASTER|$OCF_SUCCESS)
			msg="trying to gracefully shutdown LizardFS metadata server"
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Stop
# First attempt to quick stop then cleanly stop. See ManualIntervention
			lizardfs_admin_quick_stop && unlink "${master_lock}"
			metadataserver_really_stop
		;;
		$OCF_NOT_RUNNING)
			msg="tried to stop already stopped instance"
			ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_SUCCESS
		;;
		$OCF_FAILED_MASTER)
			msg="tried to stop failed master"
			ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_SUCCESS
		;;
		*)	msg="unknown state ${?}, trying to stop"
			ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
			metadataserver_really_stop
		;;
	esac
}

lizardfs_master_promote() {
	lizardfs_master_monitor
	case $? in
		$OCF_RUNNING_MASTER)
			msg="LizardFS metadata server already running as master"
			ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_SUCCESS
		;;
		$OCF_SUCCESS)
			msg="LizardFS metadata server is shadow master, promoting to master"
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"

			local cluster_metadata_version=$(get_metadata_version)
			if [[ ( $? != 0 ) || ( ${cluster_metadata_version} == "" ) ]] ; then
				msg="Failed to obtain metadata version from cluster."
				ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
				return $OCF_ERR_GENERIC
			fi

			if [[ "${promote_mode}" == "restart" ]] ; then
				msg="running in shadow mode on cluster with no master, doing full restart"
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Master1
				if ! ( ocf_run lizardfs_master stop master && unlink "${master_lock}"\
				 && ocf_run lizardfs_master start master ) ; then
					msg="Failed to restart into master mode"
					ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
					return $OCF_FAILED_MASTER
				fi
			elif [[ "${promote_mode}" == "reload" ]] ; then
				if ! ocf_run lizardfs_admin_promote ; then
					msg="failed to reload master"
					ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
					return $OCF_FAILED_MASTER
				fi
			else
				ocf_log error "promotion to master was prevented by monitor"
#				return $OCF_SUCCESS
## ManualIntervention
# This state occurs when a master was quickly stopped. It can rejoin as a shadow but can not become the first master.
# If it attempts to do so then perm(issions/inently) fail it from the cluster until the errors are manually cleaned up.
# All Demotion and Stop actions attempt to use the lizardfs_admin_quick_stop function
# Quick stop results in an inability to start cleanly as the initial master.
# Attempting to quick stop if there are no loggers will refuse and do a full clean stop instead.
# The end result is that only the last metamaster server to be stopped will be able to start.
# In the event of all nodes failing to become initial master:
# All running nodes will have current changelog.mfs from which mfsmetarestore -a can be used.
# Then echo `mfsmetadump /var/lib/mfs/metadata.mfs | head -n 2 | cut -f5-6 -d\ ` # for versions.
# Finally crm resource cleanup lizardfs-ms # to release the desired member to become initial master.
# DAMN IT, this is not true when a shadow quick stops it is still able to be the first to start, sigh.....
## Would need to resort to manually manipulating a stopped shadows metadata files, would like to avoid.
	ocf_log error "#####"
	ocf_log error "##### If you would really like this node to become the initial master then you can run these commands:"
	ocf_log error "##### mfsmetarestore -a ; crm resource cleanup lizardfs-ms # to attempt to cleanup the metadata and clear errors."
	ocf_log error "##### If you do so you may be reverting to an old metedata set.  Be very sure this is what you want to do."
	ocf_log error "##### If you just want this node to attempt to rejoin as a shadow then restart or use the cleanup command."
	ocf_log error "#####"
	return $OCF_ERR_PERM # exit and block node from cluster
			fi

			# Check that we are now succesfully a master
			lizardfs_master_monitor
			ret=$?
			case $ret in
				$OCF_RUNNING_MASTER)
					msg="LizardFS metadata server promoted successfully"
					ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Promote
					return $OCF_SUCCESS
				;;
				*)	msg="LizardFS metadata server failed to promote"
					ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
					return $OCF_FAILED_MASTER
				;;
			esac
		;;
		*)
			msg="LizardFS metadata server not running as shadow master, can't be promoted"
			ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_ERR_GENERIC
		;;
	esac
}

lizardfs_master_notify() {
	local type_op
	type_op="${OCF_RESKEY_CRM_meta_notify_type}-${OCF_RESKEY_CRM_meta_notify_operation}"

	ocf_log debug "Received $type_op notification"
	lizardfs_master_monitor
	if [ $? -eq $OCF_SUCCESS ] ; then
		msg="We're a shadow master node" # We're a shadow master node
		ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
		case $type_op in
			pre-promote)
				# Start replicating from the new master
				local new_master=$OCF_RESKEY_CRM_meta_notify_promote_uname
				msg="Changing master to $new_master"
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
				# TODO
				# call:
				# lizardfs-admin force-reconnet ${host} ${port}
			;;
			*)
				msg="Notify type_op: $type_op"
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
			;;
		esac
	else
		msg="lizardfs_master_monitor returned $?"
		ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	fi

	return $OCF_SUCCESS
}

lizardfs_master_demote() {
	lizardfs_master_monitor
	case $? in
		$OCF_RUNNING_MASTER)
			# Node may refuse to quickly stop if there are no shadows present, but that is ok
			msg="LizardFS metadata server running as master, demoting"
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Demote
			ocf_run lizardfs_admin_quick_stop && unlink "${master_lock}"
		;;
		$OCF_SUCCESS)
			msg="LizardFS metadata server already a shadow master"
			ocf_log info "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_SUCCESS
		;;
		*)
			msg="LizardFS metadata server not running, not a valid target for demotion"
			ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_ERR_GENERIC
		;;
	esac

# Do not bother to start the shadow again, trying to do so just causes the demotion operation to fail.
	return $OCF_SUCCESS # so return right now instead
# Perhaps we could call the lizardfs_master_start_shadow function with more success
# The following was originally a restart which does not make sense if we had just stopped.
	if ! ocf_run lizardfs_master start shadow ; then
		msg="Failed to start shadow master, demotion failed"
		ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
		return $OCF_ERR_GENERIC
	fi

	return $OCF_SUCCESS
}

lizardfs_admin_promote() {
	local host
	if [ "$matocl_host" = "*" ] ; then
		host=localhost
	else
		host=$matocl_host
	fi
	echo -n "${admin_password}" | lizardfs-admin promote-shadow "${host}" ${matocl_port}
}

lizardfs_probe() {
	# Probe this server and return the metadataserver-status information
	local host
	if [ "$matocl_host" = "*" ] ; then
		host=localhost
	else
		host=$matocl_host
	fi
# Error: Can't connect to 127.0.0.1:9421: ENOTCONN (Transport endpoint is not connected)
## While stopping shadow master, stopping initial master, or starting initial master.
# Error: Can't read data from socket: timeout
## While starting shadow master and reintegrating new metadata received from master.
# Send errors to stdin so we can determine status of service which is not responding to network probes:
	probe_results=$(lizardfs-admin metadataserver-status --porcelain "${host}" "$matocl_port" 2>&1)
        ret=$?
        if [ $ret -eq 0 ] ; then # exited clean so just return the results
		echo "$probe_results"
	else # existed with an error so trying to making some reasonable assumptions
		if   [[ "$probe_results" =~ "ENOTCONN (Transport endpoint is not connected)" ]]\
		 && [[ ! -z `pgrep -f "initial-personality=shadow start"` ]] ; then
			echo -e "shadow\tstopping"
# Can not rely on checking for recent file activity but considered it:
#		elif [ ! -z `find ${data_dir}/ -mmin -1`    ] ; then # Watch for any 1 minute or newer files
#		elif [ ! -z `find ${data_dir}/ -mmin -0.02` ] ; then # Watch for any ~1second or newer files
		elif [[ "$probe_results" =~ "ENOTCONN (Transport endpoint is not connected)" ]]\
		 && [[ ! -z `pgrep -f "initial-personality=master start"` ]] ; then
			echo -e "master\tstopping"
# Can not determine the difference between stopping and starting initial master service.
# It is not a problem that we can not tell them apart, both are valid states which we wait on.
#			echo -e "master\tstarting"
		elif [[ "$probe_results" =~ "read data from socket: timeout" ]]\
		 && [[ ! -z `pgrep -f "initial-personality=shadow start"` ]] ; then
			echo -e "shadow\tsyncing"
#		elif [[ ! -z `pgrep -f "initial-personality=shadow start"` ]] ; then
#			echo -e "shadow\tsyncing"
#		elif [[ "$probe_results" =~ "connection failed, error: ECONNREFUSED (Connection refused)" ]]\
#		 && [[ ! -z `pgrep -f "initial-personality=shadow start"` ]] ; then
#			ocf_log error "##### mfsmetarestore -a ; crm resource cleanup lizardfs-ms"
#			echo -e "master\tunclean"
## Attempting to catch the quick stopped master which can only become a shadow or would require mfsmetarestore -a
		else
			echo -e "unknown\tunknown\t$probe_results"
		fi
	fi
}

lizardfs_admin_quick_stop() {
	# Stop metadata server without saving metadata to file
	echo -n "${admin_password}" | \
		lizardfs-admin stop-master-without-saving-metadata "${matocl_host}" "$matocl_port"
	msg="LizardFS metadata server quickly stopping."
	ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-QStop
}

update_master_score() {
	ocf_run ${HA_SBIN_DIR}/crm_master -l reboot -v $1
}

set_metadata_version() {
	msg="LizardFS: setting cluster metadata version: ${1}"
	ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
	ocf_run ${HA_SBIN_DIR}/crm_attribute --lifetime=forever --type=crm_config --name=${metadata_version_attribute_name} --update="${1}"
}

get_metadata_version() {
	${HA_SBIN_DIR}/crm_attribute --type=crm_config --name ${metadata_version_attribute_name} --default=0 --query --quiet
}

# Extract version from metadata file
get_metadata_version_from_file() {
	mfsmetadump "${master_metadata}" | head -n 2 | awk 'BEGIN{v="0"}/^# maxnodeid/{v=$6}END{print v}'
	return 0
}

# Check if the mfsmaster process is running on this machine, and if so
# check if it is as a master or a shadow master.
# Sets global variable "promote_mode".
lizardfs_master_monitor() {
	ocf_run -info lizardfs_master isalive
	ret=$?

	if [ $ret -eq 0 ] ; then
		# mfsmaster is running, check to see if we're a shadow master or full
		# master
		probe_result=$(lizardfs_probe)
		if [ $? -ne 0 ] ; then
			msg="failed to query LizardFS master status"
			ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_ERR_GENERIC
		fi
		local personality=$(echo "$probe_result" | cut -f1)
		local connection=$(echo "$probe_result" | cut -f2)
		local metadata_version=$(echo "$probe_result" | cut -f3)
		promote_mode="prevent"
		case "$personality/$connection" in
			master/running)
				msg="running in master mode"
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
				update_master_score ${score_master}
				set_metadata_version "${metadata_version}"
				return $OCF_RUNNING_MASTER
			;;
			master/stopping)
				msg="running in master mode and stopping or starting."
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
				update_master_score ${score_shadow_no_metadata}
				return $OCF_RUNNING_MASTER
#				return $OCF_SUCCESS
			;;
#			master/starting)
#				msg="running in master mode starting up."
#				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
#				update_master_score ${score_shadow_no_metadata}
#				return $OCF_SUCCESS
#			;;
			shadow/stopping)
				msg="running in shadow mode and stopping."
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
				# Do not promote shadow if it is shutting down.
				update_master_score ${score_shadow_no_metadata}
				return $OCF_SUCCESS
			;;
			shadow/syncing)
				msg="running in shadow mode, syncing with master."
				ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
				# Do not promote shadow which is syncing up to the master during startup
				update_master_score ${score_shadow_no_metadata}
				return $OCF_SUCCESS
			;;
			shadow/connected|shadow/disconnected)
				local cluster_metadata_version=$(get_metadata_version)
				if [[ ( $? != 0 ) || ( ${cluster_metadata_version} == "" ) ]] ; then
					msg="Failed to obtain metadata version from cluster."
					ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
					return $OCF_ERR_GENERIC
				fi
				if [[ ${metadata_version} -gt 0 ]] ; then
					local local_metadata_version="${metadata_version}"
					local in_memory=1
				else
					local local_metadata_version=$(get_metadata_version_from_file)
				fi
				if [ ${local_metadata_version} -ge ${cluster_metadata_version} ] ; then
					msg="running in shadow mode, have latest metadata: ${local_metadata_version}"
					ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
					update_master_score ${score_shadow_lastest}
					if [[ $in_memory ]] ; then
						promote_mode="reload"
					else
						promote_mode="restart"
					fi
				elif [[ ${local_metadata_version} -gt 0 && ${in_memory} ]] ; then
					msg="running in shadow mode, latest metadata is not available: ${local_metadata_version} < ${cluster_metadata_version}"
					ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
					update_master_score ${score_shadow_connected}
					promote_mode="reload"
				else
					msg="running in shadow mode, no metadata."
					ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
					# Do not promote shadow with no metadata!
					update_master_score ${score_shadow_no_metadata}
				fi
				return $OCF_SUCCESS
			;;
			*)
				msg="unexpected output from lizardfs-admin: $probe_result"
				ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
				return $OCF_ERR_GENERIC
			;;
		esac
	elif [ $ret -eq 1 ] ; then
		if [ ! -e "$master_lock" ] ; then
			msg="LizardFS metadata server not running (clean)."
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_NOT_RUNNING
		else
			msg="LizardFS metadata server has failed"
			ocf_log warn "$msg" ; test $debug && ocf_log notice "$msg"
ocf_log error "#####"
ocf_log error "##### This node may have crashed, Try: rm ${master_lock} && crm resource cleanup lizardfs-ms"
ocf_log error "#####"
#unlink "${master_lock}"
			return $OCF_FAILED_MASTER
		fi
	else
		msg="error checking if master is running"
		ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
		return $OCF_ERR_GENERIC
	fi
}

lizardfs_master_reload() {
	# TODO - may need to check which parameters may be reloaded
	# vs. requiring a restart.

	lizardfs_master_monitor
	case $? in
		$OCF_RUNNING_MASTER|$OCF_SUCCESS)
			msg="reloading LizardFS metadata server configuration"
			ocf_log debug "$msg" ; test $debug && ocf_log notice "$msg"
			test $debug && touch $debug_state_change_logs/lfs-`date +\%Y\%m\%d.\%H\%M\%S`-Reload
			if ocf_run lizardfs_master reload ; then
				return $OCF_SUCCESS
			else
				return $OCF_ERR_GENERIC
			fi
		;;
		*)
			msg="no process running to reload"
			ocf_log error "$msg" ; test $debug && ocf_log notice "$msg"
			return $OCF_ERR_GENERIC
		;;
	esac
}

ensure_dirs() {
	# ensure that the metadata dir exists
	if ! mkdir -p "$data_dir" ; then
		return $OCF_ERR_PERM
	fi
	if ! chmod 0755 "$data_dir" ; then
		return $OCF_ERR_PERM
	fi
	if ! chown -R $lizardfs_user:$lizardfs_group "$data_dir" ; then
		return $OCF_ERR_PERM
	fi
	if [ ! -e "$data_dir"/metadata.mfs ] ; then
		if [ ! -e "$data_dir"/metadata.mfs.back ] ; then
			if ! echo "MFSM NEW" > "$data_dir"/metadata.mfs ; then
				return $OCF_ERR_PERM
			fi
		fi
	fi
}

lizardfs_master_validate() {
	# We need to at least have the master and metalogger binaries installed
	# for this to be able to function as an LizardFS metadata server/mfs-metalogger
	# master/slave node.
	check_binary mfsmaster
	check_binary lizardfs-admin

	if [[ "${failover_ip}" == "" ]] ; then
		msg="MASTER_HOST not set in $OCF_RESKEY_master_cfg"
		ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
		exit $OCF_ERR_CONFIGURED
	fi

	if [ "x${admin_password}" = "x" ] ; then
		msg="ADMIN_PASSWORD not set in $OCF_RESKEY_master_cfg"
		ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
		exit $OCF_ERR_CONFIGURED
	fi

	if ! [ -e "$OCF_RESKEY_master_cfg" ] ; then
		msg="mfsmaster.cfg not found at $OCF_RESKEY_master_cfg"
		ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
		exit $OCF_ERR_CONFIGURED
	fi
	if ! [ -e "$exports_cfg" ] ; then
		msg="mfsexports.cfg not found at $exports_cfg"
		ocf_log err "$msg" ; test $debug && ocf_log notice "$msg"
		exit $OCF_ERR_CONFIGURED
	fi

	# Ensure that LizardFS metadata server and mfs-metalogger are not set to load at
	# boot; if we're managing them via the resource agent, they should
	# not be loaded by init
}

if [ $# -ne 1 ] ; then
	usage
	exit $OCF_ERR_ARGS
fi

case "$1" in
	meta-data)
		lizardfs_ra_metadata
		exit $OCF_SUCCESS
	;;
	usage|help)
		usage
		exit $OCF_SUCCESS
	;;
esac

# All actions besides metadata and usage must pass validation
lizardfs_master_validate

case "$1" in
	start)    lizardfs_master_start_shadow;;
	stop)     lizardfs_master_stop;;
	monitor)  lizardfs_master_monitor;;
	reload)   lizardfs_master_reload;;
	promote)  lizardfs_master_promote;;
	demote)   lizardfs_master_demote;;
	notify)   lizardfs_master_notify;;
	# We have already validated by now
	validate-all) ;;
	*)        usage; exit $OCF_ERR_UNIMPLEMENTED;;
esac

rc=$?
ocf_log debug "${OCF_RESOURCE_INSTANCE} ${__OCF_ACTION} : $rc"
exit $rc
